{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29jrFfEHyQS2",
        "outputId": "1fa4c89d-5dc6-401a-fafd-f24503184253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylhe in /usr/local/lib/python3.11/dist-packages (0.9.1)\n",
            "Requirement already satisfied: awkward>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pylhe) (2.8.2)\n",
            "Requirement already satisfied: graphviz>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from pylhe) (0.20.3)\n",
            "Requirement already satisfied: particle>=0.16 in /usr/local/lib/python3.11/dist-packages (from pylhe) (0.25.3)\n",
            "Requirement already satisfied: vector>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from pylhe) (1.6.2)\n",
            "Requirement already satisfied: awkward-cpp==45 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.2.0->pylhe) (45)\n",
            "Requirement already satisfied: fsspec>=2022.11.0 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.2.0->pylhe) (2025.3.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.2.0->pylhe) (8.7.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from awkward>=1.2.0->pylhe) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from awkward>=1.2.0->pylhe) (24.2)\n",
            "Requirement already satisfied: attrs>=19.2 in /usr/local/lib/python3.11/dist-packages (from particle>=0.16->pylhe) (25.3.0)\n",
            "Requirement already satisfied: hepunits>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from particle>=0.16->pylhe) (2.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from particle>=0.16->pylhe) (4.13.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.13.0->awkward>=1.2.0->pylhe) (3.21.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pylhe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lyneF0pIYUfo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2\n",
        "import pylhe\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j1sFhMYul--m"
      },
      "outputs": [],
      "source": [
        "# Pi0 mass\n",
        "Mpi0 = 0.1349768\n",
        "\n",
        "# epsilon^2\n",
        "eps2 = [1e-10, 1.4e-10, 2e-10, 1e-9, 1-3e-9, 1e-8]\n",
        "\n",
        "# Dark photon mass\n",
        "mA = [1e-1, 5e-2, 1e-2]\n",
        "\n",
        "def scale_factor(eps2,mA):\n",
        "  return ( 2 * eps2 * (1 - mA**2/Mpi0**2)**3 )\n",
        "\n",
        "# factor to scale signal to a year\n",
        "def signal_factor(eps2, mA, signal):\n",
        "  return scale_factor(eps2, mA) * 2e22 / len(signal)\n",
        "\n",
        "# factor to adjust signal to an eps2\n",
        "def eps_factor(eps2):\n",
        "  return eps2 / (5e-3)**2\n",
        "\n",
        "# factor to scale background to a year\n",
        "bckg_factor = 1.1e21 / 515500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGAuF4emtSW9"
      },
      "source": [
        "# Turning all madDump data into dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uEYjyoU0tkQx"
      },
      "outputs": [],
      "source": [
        "eventsM1 = []\n",
        "eventsM2 = []\n",
        "eventsM3 = []\n",
        "\n",
        "with open(\"events_mass1.lhe\", \"r\") as fM1:\n",
        "    linesM1 = fM1.readlines()\n",
        "\n",
        "with open(\"events_mass2.lhe\", \"r\") as fM2:\n",
        "   linesM2 = fM2.readlines()\n",
        "\n",
        "with open(\"events_mass3.lhe\", \"r\") as fM3:\n",
        "    linesM3 = fM3.readlines()\n",
        "\n",
        "\n",
        "######### Mass1 ##########\n",
        "inside_eventM1 = False\n",
        "for lineM1 in linesM1:\n",
        "    if \"<event>\" in lineM1:\n",
        "        inside_eventM1 = True\n",
        "        event_dataM1 = []\n",
        "        continue\n",
        "    elif \"</event>\" in lineM1:\n",
        "        inside_eventM1 = False\n",
        "        for pdata in event_dataM1:\n",
        "            eventsM1.append(pdata)\n",
        "        continue\n",
        "\n",
        "    if inside_eventM1:\n",
        "        try:\n",
        "            split = lineM1.strip().split()\n",
        "            if len(split) == 13:  # typical number of columns per particle\n",
        "                pdg_id = int(split[0])\n",
        "                status = int(split[1])\n",
        "                px = float(split[6])\n",
        "                py = float(split[7])\n",
        "                pz = float(split[8])\n",
        "                E = float(split[9])\n",
        "                m = float(split[10])\n",
        "                eventsM1.append({\n",
        "                    \"id\": pdg_id,\n",
        "                    \"status\": status,\n",
        "                    \"px\": px,\n",
        "                    \"py\": py,\n",
        "                    \"pz\": pz,\n",
        "                    \"E\": E,\n",
        "                    \"m\": m\n",
        "                })\n",
        "        except:\n",
        "            continue  # skip malformed lines\n",
        "\n",
        "######### Mass2 ##########\n",
        "inside_eventM2 = False\n",
        "for lineM2 in linesM2:\n",
        "    if \"<event>\" in lineM2:\n",
        "        inside_eventM2 = True\n",
        "        event_dataM2 = []\n",
        "        continue\n",
        "    elif \"</event>\" in lineM2:\n",
        "        inside_eventM2 = False\n",
        "        for pdata in event_dataM2:\n",
        "            eventsM2.append(pdata)\n",
        "        continue\n",
        "\n",
        "    if inside_eventM2:\n",
        "        try:\n",
        "            split = lineM2.strip().split()\n",
        "            if len(split) == 13:  # typical number of columns per particle\n",
        "                pdg_id = int(split[0])\n",
        "                status = int(split[1])\n",
        "                px = float(split[6])\n",
        "                py = float(split[7])\n",
        "                pz = float(split[8])\n",
        "                E = float(split[9])\n",
        "                m = float(split[10])\n",
        "                eventsM2.append({\n",
        "                    \"id\": pdg_id,\n",
        "                    \"status\": status,\n",
        "                    \"px\": px,\n",
        "                    \"py\": py,\n",
        "                    \"pz\": pz,\n",
        "                    \"E\": E,\n",
        "                    \"m\": m\n",
        "                })\n",
        "        except:\n",
        "            continue  # skip malformed lines\n",
        "\n",
        "\n",
        "######### Mass3 ##########\n",
        "inside_eventM3 = False\n",
        "for lineM3 in linesM3:\n",
        "    if \"<event>\" in lineM3:\n",
        "        inside_eventM3 = True\n",
        "        event_dataM3 = []\n",
        "        continue\n",
        "    elif \"</event>\" in lineM3:\n",
        "        inside_eventM3 = False\n",
        "        for pdata in event_dataM3:\n",
        "            eventsM3.append(pdata)\n",
        "        continue\n",
        "\n",
        "    if inside_eventM3:\n",
        "        try:\n",
        "            split = lineM3.strip().split()\n",
        "            if len(split) == 13:  # typical number of columns per particle\n",
        "                pdg_id = int(split[0])\n",
        "                status = int(split[1])\n",
        "                px = float(split[6])\n",
        "                py = float(split[7])\n",
        "                pz = float(split[8])\n",
        "                E = float(split[9])\n",
        "                m = float(split[10])\n",
        "                eventsM3.append({\n",
        "                    \"id\": pdg_id,\n",
        "                    \"status\": status,\n",
        "                    \"px\": px,\n",
        "                    \"py\": py,\n",
        "                    \"pz\": pz,\n",
        "                    \"E\": E,\n",
        "                    \"m\": m\n",
        "                })\n",
        "        except:\n",
        "            continue  # skip malformed lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4zTbH1Dptdt5"
      },
      "outputs": [],
      "source": [
        "dfM1 = pd.DataFrame(eventsM1)\n",
        "dfM2 = pd.DataFrame(eventsM2)\n",
        "dfM3 = pd.DataFrame(eventsM3)\n",
        "\n",
        "# filtering photon energy between 1GeV and 40GeV\n",
        "signalM1 = dfM1[(dfM1['E'] >= 1) & (dfM1['E'] <= 40) & (dfM1['id']==22)][['E']]\n",
        "signalM2 = dfM2[(dfM2['E'] >= 1) & (dfM2['E'] <= 40) & (dfM2['id']==22)][['E']]\n",
        "signalM3 = dfM3[(dfM3['E'] >= 1) & (dfM3['E'] <= 40) & (dfM3['id']==22)][['E']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ-woxlEkzhD"
      },
      "source": [
        "# Turning Geant4 data into dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CXkTMEZpRn4B"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"gammaPiZeroExit.txt\", delimiter=',', on_bad_lines=\"skip\", index_col=False)\n",
        "\n",
        "# Convert all columns to numeric, invalid parsing will be set as NaN\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop rows where any element is NaN\n",
        "df.dropna(inplace=True)\n",
        "background = df[(df['energy'] >= 1000) & (df['energy'] <= 40000)]  # in MeV\n",
        "background = background['energy'] / 1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKKFFz5Rj4xm"
      },
      "source": [
        "# Turning continuous data from background into histogram bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ypuMC5KKZZeQ"
      },
      "outputs": [],
      "source": [
        "num_bins = 12\n",
        "bin_edges = np.linspace(1, 40, num_bins + 1)\n",
        "\n",
        "# turning into arrays with 12 elements, each with the number of counts in each bin\n",
        "background_hist , _ = np.histogram(background, bins=bin_edges)\n",
        "signalM1_hist , _ = np.histogram(signalM1, bins=bin_edges)\n",
        "signalM2_hist , _ = np.histogram(signalM2, bins=bin_edges)\n",
        "signalM3_hist , _ = np.histogram(signalM3, bins=bin_edges)\n",
        "signal_hist=[signalM1_hist, signalM2_hist, signalM3_hist]\n",
        "\n",
        "background_hist = np.where(background_hist == 0, 0.1, background_hist) # avoid 0 so that everything scales smoothly\n",
        "# Background in a year\n",
        "H0 = background_hist * bckg_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2K7iKqWCOP7"
      },
      "source": [
        "## Chi2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg3rRavl2Vm3"
      },
      "source": [
        "# chi2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3IxFbiTWdz0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5128e876-4246-47cd-e6c1-1caaed41cba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dark photon mass:  0.1\n",
            "Signal factor: 55226463201\n",
            "Chi²: 18.209871552796432\n",
            "p-value:  0.10946510710618824\n",
            "eps2:  1.3e-09\n",
            "\n",
            "\n",
            "............................\n"
          ]
        }
      ],
      "source": [
        "def sample_bins_in_chunks(size, p, n_bins, batch_size=100000):\n",
        "    total_counts = np.zeros(n_bins, dtype=int)    # bin counts will be stored here\n",
        "    full_batches = size // batch_size             # numer of batches of 100000 elements\n",
        "    remainder = size % batch_size                 # the missing batches\n",
        "\n",
        "    for _ in range(full_batches):\n",
        "        bins = np.random.choice(n_bins, size=batch_size, p=p)    # samples bin indices 100000 times with probabilities p\n",
        "        total_counts += np.bincount(bins, minlength=n_bins)      # adds the counts to each bin\n",
        "\n",
        "    if remainder > 0:\n",
        "        bins = np.random.choice(n_bins, size=remainder, p=p)    # does the same for the rest of the batch\n",
        "        total_counts += np.bincount(bins, minlength=n_bins)\n",
        "\n",
        "    return total_counts\n",
        "\n",
        "\n",
        "for i in range(0,1):\n",
        "  for e in eps2:\n",
        "      # signal in a year for epsilon = e\n",
        "      signal = signal_hist[i] * signal_factor(e, mA[i], signal_hist[i]) * eps_factor(e)\n",
        "\n",
        "      # amount of pi0 that decay to gamma + A'\n",
        "      factor = math.ceil(scale_factor(e, mA[i]) * np.sum(H0))\n",
        "\n",
        "      # normalize the histograms to probability distributions\n",
        "      H0_probs = H0 / np.sum(H0)\n",
        "      signal_probs = signal / np.sum(signal)\n",
        "\n",
        "      remove_counts = sample_bins_in_chunks(size=2*factor, p=H0_probs, n_bins=len(H0))\n",
        "      add_counts = sample_bins_in_chunks(size=factor, p=signal_probs, n_bins=len(H0))\n",
        "\n",
        "      H1 = H0 - remove_counts + add_counts\n",
        "      H1 = np.clip(H1, 0, None)\n",
        "\n",
        "      epsilon = 1e-12\n",
        "      chi2_stat = np.sum((H0 - H1)**2 / H1+epsilon)\n",
        "\n",
        "      print(f\"Dark photon mass: \", mA[i])\n",
        "      pvalue=chi2.sf(chi2_stat,12)\n",
        "      print(\"Signal factor:\", factor)\n",
        "      print(\"Chi²:\", chi2_stat)\n",
        "      print(f\"p-value: \", pvalue)\n",
        "      print(f\"eps2: \", e)\n",
        "      print(\"\")\n",
        "      print(\"\")\n",
        "\n",
        "  print(\"............................\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}